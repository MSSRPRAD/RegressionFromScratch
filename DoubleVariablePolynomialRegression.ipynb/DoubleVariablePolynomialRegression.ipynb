{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double Variable Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../DoubleVariablePolynomialRegression.ipynb/data/Fish.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: No NAN Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Height'] = (df['Height']-np.mean(df['Height']))/np.std(df['Height'])\n",
    "df['Width'] = (df['Width']-np.mean(df['Width']))/np.std(df['Width'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Random Test and Train Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 420\n",
    "train_fraction = 0.8\n",
    "train = df.sample(frac=train_fraction, random_state=seed)\n",
    "test = df.drop(train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolynomialRegressionModel:\n",
    "    def __init__(self, degree, q, lmbda):\n",
    "        \"\"\"\n",
    "        Polynomial Regression Model for some particular degree.\n",
    "        \"\"\"\n",
    "        self.train_errors = {}\n",
    "        self.test_errors = {}\n",
    "        self.q = q\n",
    "        self.lmbda = lmbda\n",
    "        self.degree = degree\n",
    "        # Initialize Weights\n",
    "        self.weights = np.random.rand(degree+1, degree+1)\n",
    "\n",
    "    def calculate_loss(self, X_i, t_i):\n",
    "        # print('inside self.calculate_loss()')\n",
    "        assert type(X_i[0]) == np.float64 and type(t_i) == np.float64 and type(X_i[1]) == np.float64, \"Types are not matching. Check!\"\n",
    "\n",
    "        a = X_i[0]\n",
    "        b = X_i[1]\n",
    "        t = t_i\n",
    "        prediction = self.predict([(a, b)])\n",
    "        # print('predicted:')\n",
    "        # print(prediction)\n",
    "        # print('expected')\n",
    "        # print(t)\n",
    "\n",
    "        grad = np.zeros_like(self.weights)\n",
    "        grad.fill(0.0)\n",
    "        for i in range(self.degree+1):\n",
    "            for j in range(self.degree+1):\n",
    "                if i + j <= self.degree:\n",
    "                    grad[i][j] = (a**i)*(b**j)*(t - prediction)\n",
    "        \n",
    "        grad += (self.lmbda*self.q//2)*(np.abs(self.weights)**(self.q-1))\n",
    "        # print('loss: ')\n",
    "        # print(grad)\n",
    "        return -1*grad\n",
    "\n",
    "    def fit(self, X_train, y_train, X_test, y_test, lr=0.01, epochs=500, batch_size=20):\n",
    "        \"\"\"\n",
    "        Fit the polynomial regression model using Batch Gradient Descent.\n",
    "\n",
    "        Parameters:\n",
    "        X_train: Input Feature variables.\n",
    "        y_train: Target Variable\n",
    "        X_test: Input Feature variables for test data\n",
    "        y_test: Target Variables for test data\n",
    "        lr: Learning Rate for Gradient Descent\n",
    "        epochs: No of Epochs to train\n",
    "\n",
    "        Returns:\n",
    "        NA\n",
    "        \"\"\"\n",
    "        print('Starting Training.....')\n",
    "        X_train = np.array(X_train)\n",
    "        y_train = np.array(y_train)\n",
    "        # print(X_train.head())\n",
    "        for epoch in range(epochs):\n",
    "            count = 0\n",
    "            loss = np.zeros_like(self.weights)\n",
    "            # print(X_train.shape[0])\n",
    "            \n",
    "            for i in range(X_train.shape[0]):\n",
    "                # print('sample')\n",
    "                # print(X_train[i][0])\n",
    "                # print(X_train[i][1])\n",
    "                # print(y_train[i])\n",
    "                if epoch == 0 or (epoch*epochs+i)%(X_train.shape[0]/2):\n",
    "                    self.train_errors[epoch*epochs + i] = self.calculate_error(X_train, y_train)\n",
    "                    self.test_errors[epoch*epochs + i] = self.calculate_error(X_test, y_test)\n",
    "\n",
    "                X_i = (X_train[i][0],X_train[i][1])\n",
    "                t_i =  y_train[i]\n",
    "\n",
    "                if count%batch_size == 0:\n",
    "                    loss /= batch_size\n",
    "                    # print('loss: ')\n",
    "                    # print(loss)\n",
    "                    # print(self.weights)\n",
    "                    # self.weights += (self.lmbda*self.q//2)*(np.abs(self.weights)**(self.q-1))\n",
    "                    self.weights -= lr*loss\n",
    "                    # print(self.weights)\n",
    "                    loss = np.zeros_like(self.weights)\n",
    "                else:\n",
    "                    loss += self.calculate_loss(X_i, t_i)\n",
    "            \n",
    "                count+=1\n",
    "            if epoch%(epochs/10) == 0:\n",
    "                print(f\"epoch: {epoch}\")\n",
    "                print(f\"Error: {self.calculate_error(X_train, y_train)}\")\n",
    "\n",
    "        return\n",
    "\n",
    "    def calculate_error(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Find the error of the model on some data.\n",
    "\n",
    "        Parameters:\n",
    "        X_test: The sample Input Feature.\n",
    "        y_test: The sample Target Feature.\n",
    "\n",
    "        Returns:\n",
    "        A float value that is the MSE b/w the predicted outputs and the target outputs.\n",
    "        \"\"\"\n",
    "        X_test = np.array(X_test)\n",
    "        y_test = np.array(y_test)\n",
    "        predictions = self.predict(X_test)\n",
    "        mse = np.mean(\n",
    "            (predictions-y_test)**2\n",
    "        )\n",
    "        return mse\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Make Predictions using the trained model.\n",
    "\n",
    "        Parameters:\n",
    "        X_test: The sample Input Features.\n",
    "\n",
    "        Returns:\n",
    "        A numpy Array with the predicted target variable value for each of the samples having\n",
    "        same dimensions as X_test.\n",
    "        \"\"\"\n",
    "        result = [] \n",
    "        for sample in X_test:\n",
    "            assert type(sample[0]) == np.float64 and type(sample[1]) == np.float64, \"Variable doesn't have the required type!\"\n",
    "            degree = 2\n",
    "            a = sample[0]\n",
    "            b = sample[1]\n",
    "            y = 0\n",
    "            for i in range(degree+1):\n",
    "                for j in range(degree+1):\n",
    "                    if i + j <= degree:\n",
    "                        y += self.weights[i][j]*(a**i)*(b**j)\n",
    "            result.append(y)\n",
    "        return np.array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for i in [1, 2, 3, 4, 5, 6, 7, 8, 9]:  \n",
    "    for j in  [1, 2, 3, 4, 5, 6, 7, 8, 9]:\n",
    "        for lr in [0.1, 0.001, 0.0001]:\n",
    "            print(f\"doing: {i}, {j}, {lr} for 500 epochs\")\n",
    "            model = PolynomialRegressionModel(i=i, j=j, q=0, lmbda=0)\n",
    "            model.fit(train.drop(['Weight'], axis=1), train['Weight'], test.drop(['Weight'], axis=1), test['Weight'], lr=lr, epochs=500)\n",
    "            errors.append({\n",
    "                \"i\": i,\n",
    "                \"j\": j,\n",
    "                \"lr\": lr,\n",
    "                \"test_errors: \": model.test_errors,\n",
    "                \"train_errors: \": model.train_errors\n",
    "            })\n",
    "            print(errors)\n",
    "json_obj = json.dumps(errors)\n",
    "with open('double_noreg.json', 'w') as fp:\n",
    "    json.dump(json_obj, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "# Note this should be chosen from analysis of previous grid search without regularization\n",
    "best_fit_degree = 2\n",
    "for degree in [best_fit_degree]:  \n",
    "    for lr in [0.01, 0.001, 0.0001]:\n",
    "        for q in [0.5, 1, 2, 4]:\n",
    "            for batch_size in [20, 1]:\n",
    "                for lmbda in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "                    print(f\"doing: {degree}, {lr}, {q}, {batch_size} for 500 epochs\")\n",
    "                    model = PolynomialRegressionModel(degree=degree, q=q, lmbda=lmbda)\n",
    "                    model.fit(train.drop(['Weight'], axis=1), train['Weight'], test.drop(['Weight'], axis=1), test['Weight'], lr=lr, epochs=500, batch_size=batch_size)\n",
    "                    errors.append({\n",
    "                        \"degree\": degree,\n",
    "                        \"lr\": lr,\n",
    "                        \"q\": q, \n",
    "                        \"lmbda\": lmbda,\n",
    "                        \"batch_size\": batch_size,\n",
    "                        \"test_errors: \": model.test_errors,\n",
    "                        \"train_errors: \": model.train_errors\n",
    "                    })\n",
    "                    print(errors)\n",
    "json_obj = json.dumps(errors)\n",
    "with open('double_withreg.json', 'w') as fp:\n",
    "    json.dump(json_obj, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PolynomialRegressionModel(degree=5, q=2, lmbda=0.1)\n",
    "model.fit(train.drop(['Weight'], axis=1), train['Weight'], test.drop(['Weight'], axis=1), test['Weight'], lr=0.001, epochs=200, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test_errors\n",
    "epochs = list(model.train_errors.keys())\n",
    "errors = list(model.train_errors.values())\n",
    "\n",
    "plt.plot(epochs, errors, marker='o')\n",
    "epochs = list(model.test_errors.keys())\n",
    "errors = list(model.test_errors.values())\n",
    "plt.plot(epochs, errors, marker='x')\n",
    "plt.title('Error vs Samples')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('Error')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_values = np.linspace(min(train.to_numpy()[:, 0]), max(train.to_numpy()[:, 0]), 100)\n",
    "b_values = np.linspace(min(test.to_numpy()[:, 1]), max(train.to_numpy()[:, 1]), 100)\n",
    "a_mesh, b_mesh = np.meshgrid(a_values, b_values)\n",
    "\n",
    "prediction_points = np.c_[a_mesh.ravel(), b_mesh.ravel()]\n",
    "predictions = model.predict(prediction_points)\n",
    "predictions_surface = predictions.reshape(a_mesh.shape)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.plot_surface(a_mesh, b_mesh, predictions_surface, cmap='viridis')\n",
    "\n",
    "# ax.scatter((train+test .to_numpy()[:, 0], train.to_numpy()[:, 1], train['Weight'].to_numpy(), color='blue', marker='o')\n",
    "\n",
    "ax.set_xlabel('Height')\n",
    "ax.set_ylabel('Width')\n",
    "ax.set_zlabel('Predicted Weight')\n",
    "\n",
    "plt.title('3D Surface Plot of Polynomial Regression Model Predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division \n",
    "import numpy as np\n",
    "\n",
    "def compute_r2(y_true, y_predicted):\n",
    "    sse = sum((y_true - y_predicted)**2)\n",
    "    tse = (len(y_true) - 1) * np.var(y_true, ddof=1)\n",
    "    r2_score = 1 - (sse / tse)\n",
    "    return r2_score, sse, tse\n",
    "\n",
    "y_pred = model.predict(np.array(test.drop(['Weight'], axis=1)))\n",
    "y_actual = test['Weight']\n",
    "compute_r2(y_actual, y_pred)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the 45-degree line\n",
    "plt.plot([min(y_actual), max(y_actual)], [min(y_actual), max(y_actual)], linestyle='--', color='gray', label='45-degree line')\n",
    "\n",
    "# Scatter plot for y_pred and y_actual\n",
    "plt.scatter(y_actual, y_pred, color='blue', label='Scatter plot')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('y_actual')\n",
    "plt.ylabel('y_pred')\n",
    "plt.title('Scatter plot of y_pred vs y_actual')\n",
    "\n",
    "# Adding a legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
