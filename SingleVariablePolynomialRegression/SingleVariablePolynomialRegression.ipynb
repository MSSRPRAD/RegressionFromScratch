{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Variable Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/mpradyumna/RegressionFromScratch/.venv/lib64/python3.11/site-packages (1.26.0)\n",
      "Requirement already satisfied: pandas in /home/mpradyumna/RegressionFromScratch/.venv/lib64/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: matplotlib in /home/mpradyumna/RegressionFromScratch/.venv/lib64/python3.11/site-packages (3.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mpradyumna/RegressionFromScratch/.venv/lib64/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mpradyumna/RegressionFromScratch/.venv/lib64/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/mpradyumna/RegressionFromScratch/.venv/lib64/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/mpradyumna/RegressionFromScratch/.venv/lib64/python3.11/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/mpradyumna/RegressionFromScratch/.venv/lib64/python3.11/site-packages (from matplotlib) (0.12.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/mpradyumna/RegressionFromScratch/.venv/lib64/python3.11/site-packages (from matplotlib) (4.43.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/mpradyumna/RegressionFromScratch/.venv/lib64/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mpradyumna/RegressionFromScratch/.venv/lib64/python3.11/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/mpradyumna/RegressionFromScratch/.venv/lib64/python3.11/site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/mpradyumna/RegressionFromScratch/.venv/lib64/python3.11/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/mpradyumna/RegressionFromScratch/.venv/lib64/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy pandas matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../SingleVariablePolynomialRegression/data/Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.987988</td>\n",
       "      <td>5.098368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.719720</td>\n",
       "      <td>2.516654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.403403</td>\n",
       "      <td>0.337961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.107107</td>\n",
       "      <td>0.737320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.345345</td>\n",
       "      <td>-0.780955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X         Y\n",
       "0  0.987988  5.098368\n",
       "1  0.719720  2.516654\n",
       "2 -0.403403  0.337961\n",
       "3  0.107107  0.737320\n",
       "4  0.345345 -0.780955"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: No NAN Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X    0\n",
       "Y    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the feature X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['X'] = (df['X']-np.mean(df['X']))/np.std(df['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.709535</td>\n",
       "      <td>5.098368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.245345</td>\n",
       "      <td>2.516654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.698017</td>\n",
       "      <td>0.337961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.185330</td>\n",
       "      <td>0.737320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.597558</td>\n",
       "      <td>-0.780955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X         Y\n",
       "0  1.709535  5.098368\n",
       "1  1.245345  2.516654\n",
       "2 -0.698017  0.337961\n",
       "3  0.185330  0.737320\n",
       "4  0.597558 -0.780955"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Random Test and Train Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 420\n",
    "train_fraction = 0.8\n",
    "train = df.sample(frac=train_fraction, random_state=seed)\n",
    "test = df.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of             X         Y\n",
       "715 -1.259202  0.035008\n",
       "353  1.591755  2.834778\n",
       "507  0.105655 -1.238693\n",
       "713  0.943968  0.730347\n",
       "553 -0.500563  0.381970\n",
       "..        ...       ...\n",
       "252 -1.435871  0.610148\n",
       "327  0.012124  0.765786\n",
       "115 -0.396640 -0.704895\n",
       "174 -0.025981  2.100271\n",
       "701 -1.629861 -0.873611\n",
       "\n",
       "[800 rows x 2 columns]>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of             X         Y\n",
       "3    0.185330  0.737320\n",
       "8   -0.670304 -0.566798\n",
       "9    0.715337  2.219073\n",
       "10  -0.012124  0.341446\n",
       "28   0.902399  1.116080\n",
       "..        ...       ...\n",
       "975  1.674894  5.692382\n",
       "983  0.348142 -0.517849\n",
       "994  0.912791  1.611825\n",
       "995  1.162207  3.079356\n",
       "996 -1.065212  0.027487\n",
       "\n",
       "[200 rows x 2 columns]>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolynomialRegressionModel:\n",
    "    def __init__(self, degree):\n",
    "        \"\"\"\n",
    "        Polynomial Regression Model for some particular degree.\n",
    "        \"\"\"\n",
    "        self.loss = None\n",
    "        self.deg = degree\n",
    "        self.weights = np.random.rand(1, degree+1)\n",
    "\n",
    "    def calculate_loss(self, input, target):\n",
    "        # print('inside self.calculate_loss()')\n",
    "        assert type(input) == float and type(target) == float, \"Types are not matching. Check!\"\n",
    "        result = []\n",
    "        prediction = self.predict([input])\n",
    "        # print('predicted:')\n",
    "        # print(prediction)\n",
    "        # print('expected')\n",
    "        # print(target)\n",
    "        for i in range(self.deg+1):\n",
    "            result.append(\n",
    "                (input**i)*(prediction-target)\n",
    "            )\n",
    "        return np.array(result).reshape(self.weights.shape)\n",
    "\n",
    "    def fit(self, X_train, y_train, lr=0.01, epochs=500, batch_size=20):\n",
    "        \"\"\"\n",
    "        Fit the polynomial regression model using Batch Gradient Descent.\n",
    "\n",
    "        Parameters:\n",
    "        X_train: Input Feature variable (only one!)\n",
    "        y_train: Target Variable\n",
    "        lr: Learning Rate for Gradient Descent\n",
    "        epochs: No of Epochs to train\n",
    "\n",
    "        Returns:\n",
    "        NA\n",
    "        \"\"\"\n",
    "        print('Starting Training.....')\n",
    "        for epoch in range(epochs):\n",
    "            count = 0\n",
    "            loss = np.zeros_like(self.weights)\n",
    "            for sample in zip(X_train, y_train):\n",
    "                input = sample[0]\n",
    "                target = sample[1]\n",
    "                # print(input, target)\n",
    "\n",
    "                if count%batch_size == 0:\n",
    "                    loss /= batch_size\n",
    "                    self.weights *= 0.995\n",
    "                    self.weights -= lr*loss\n",
    "                    loss = np.zeros_like(self.weights)\n",
    "                else:\n",
    "                    loss += self.calculate_loss(input, target)\n",
    "            \n",
    "                count+=1\n",
    "            if epochs%10 == 0:\n",
    "                print(f\"epoch: {epoch}\")\n",
    "                print(f\"Error: {self.calculate_error(X_train, y_train)}\")\n",
    "\n",
    "        return\n",
    "\n",
    "    def calculate_error(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Find the error of the model on some data.\n",
    "\n",
    "        Parameters:\n",
    "        X_test: The sample Input Feature.\n",
    "        y_test: The sample Target Feature.\n",
    "\n",
    "        Returns:\n",
    "        A float value that is the MSE b/w the predicted outputs and the target outputs.\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X_test)\n",
    "        mse = np.mean(\n",
    "            (predictions-y_test)**2\n",
    "        )\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Make Predictions using the trained model.\n",
    "\n",
    "        Parameters:\n",
    "        X_test: The sample Input Features.\n",
    "\n",
    "        Returns:\n",
    "        A numpy Array with the predicted target variable value for each of the samples having\n",
    "        same dimensions as X_test.\n",
    "        \"\"\"\n",
    "        result = [] \n",
    "        for sample in X_test:\n",
    "            assert type(sample) == float, \"Variable doesn't have the required type!\"\n",
    "            arr = np.array([sample**i for i in range(self.deg+1)]).reshape(1, self.deg+1)\n",
    "            result.append(arr.dot(self.weights.T)[0][0])\n",
    "            \n",
    "        return np.array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training.....\n",
      "epoch: 0\n",
      "loss: -2.740933011120583\n",
      "epoch: 1\n",
      "loss: -2.528273438158995\n",
      "epoch: 2\n",
      "loss: -2.473324368902075\n",
      "epoch: 3\n",
      "loss: -2.4492626945794194\n",
      "epoch: 4\n",
      "loss: -2.4335979702721966\n",
      "epoch: 5\n",
      "loss: -2.421541769573299\n",
      "epoch: 6\n",
      "loss: -2.411763844508493\n",
      "epoch: 7\n",
      "loss: -2.403732025938588\n",
      "epoch: 8\n",
      "loss: -2.397133578971849\n",
      "epoch: 9\n",
      "loss: -2.3917323233698604\n",
      "epoch: 10\n",
      "loss: -2.3873307612398786\n",
      "epoch: 11\n",
      "loss: -2.3837594458029163\n",
      "epoch: 12\n",
      "loss: -2.38087321516921\n",
      "epoch: 13\n",
      "loss: -2.3785488313300007\n",
      "epoch: 14\n",
      "loss: -2.37668271597191\n",
      "epoch: 15\n",
      "loss: -2.375188609793741\n",
      "epoch: 16\n",
      "loss: -2.373995243477256\n",
      "epoch: 17\n",
      "loss: -2.373044127907912\n",
      "epoch: 18\n",
      "loss: -2.3722875362412257\n",
      "epoch: 19\n",
      "loss: -2.371686713447541\n",
      "epoch: 20\n",
      "loss: -2.3712103217550293\n",
      "epoch: 21\n",
      "loss: -2.3708331131568885\n",
      "epoch: 22\n",
      "loss: -2.370534810480536\n",
      "epoch: 23\n",
      "loss: -2.370299174021244\n",
      "epoch: 24\n",
      "loss: -2.370113229541369\n",
      "epoch: 25\n",
      "loss: -2.369966634203165\n",
      "epoch: 26\n",
      "loss: -2.3698511588474225\n",
      "epoch: 27\n",
      "loss: -2.3697602673761593\n",
      "epoch: 28\n",
      "loss: -2.3696887764864227\n",
      "epoch: 29\n",
      "loss: -2.3696325814227412\n",
      "epoch: 30\n",
      "loss: -2.369588435650484\n",
      "epoch: 31\n",
      "loss: -2.369553774348039\n",
      "epoch: 32\n",
      "loss: -2.369526573354788\n",
      "epoch: 33\n",
      "loss: -2.369505236701239\n",
      "epoch: 34\n",
      "loss: -2.3694885071054337\n",
      "epoch: 35\n",
      "loss: -2.3694753948708493\n",
      "epoch: 36\n",
      "loss: -2.3694651214912437\n",
      "epoch: 37\n",
      "loss: -2.369457074983726\n",
      "epoch: 38\n",
      "loss: -2.369450774556024\n",
      "epoch: 39\n",
      "loss: -2.3694458426896596\n",
      "epoch: 40\n",
      "loss: -2.3694419831055114\n",
      "epoch: 41\n",
      "loss: -2.3694389633888338\n",
      "epoch: 42\n",
      "loss: -2.3694366013002472\n",
      "epoch: 43\n",
      "loss: -2.369434753999257\n",
      "epoch: 44\n",
      "loss: -2.3694333095667095\n",
      "epoch: 45\n",
      "loss: -2.369432180340128\n",
      "epoch: 46\n",
      "loss: -2.3694312976774565\n",
      "epoch: 47\n",
      "loss: -2.3694306078452714\n",
      "epoch: 48\n",
      "loss: -2.369430068791671\n",
      "epoch: 49\n",
      "loss: -2.369429647614646\n",
      "epoch: 50\n",
      "loss: -2.369429318576926\n",
      "epoch: 51\n",
      "loss: -2.3694290615499125\n",
      "epoch: 52\n",
      "loss: -2.3694288607944323\n",
      "epoch: 53\n",
      "loss: -2.369428704005711\n",
      "epoch: 54\n",
      "loss: -2.369428581565529\n",
      "epoch: 55\n",
      "loss: -2.3694284859567785\n",
      "epoch: 56\n",
      "loss: -2.3694284113053072\n",
      "epoch: 57\n",
      "loss: -2.369428353021416\n",
      "epoch: 58\n",
      "loss: -2.369428307519435\n",
      "epoch: 59\n",
      "loss: -2.3694282719983843\n",
      "epoch: 60\n",
      "loss: -2.3694282442704946\n",
      "epoch: 61\n",
      "loss: -2.369428222627117\n",
      "epoch: 62\n",
      "loss: -2.3694282057339056\n",
      "epoch: 63\n",
      "loss: -2.3694281925489147\n",
      "epoch: 64\n",
      "loss: -2.3694281822585888\n",
      "epoch: 65\n",
      "loss: -2.3694281742277354\n",
      "epoch: 66\n",
      "loss: -2.3694281679604665\n",
      "epoch: 67\n",
      "loss: -2.3694281630696583\n",
      "epoch: 68\n",
      "loss: -2.369428159253124\n",
      "epoch: 69\n",
      "loss: -2.3694281562749806\n",
      "epoch: 70\n",
      "loss: -2.3694281539511226\n",
      "epoch: 71\n",
      "loss: -2.3694281521378517\n",
      "epoch: 72\n",
      "loss: -2.3694281507230133\n",
      "epoch: 73\n",
      "loss: -2.369428149619088\n",
      "epoch: 74\n",
      "loss: -2.369428148757767\n",
      "epoch: 75\n",
      "loss: -2.3694281480857464\n",
      "epoch: 76\n",
      "loss: -2.369428147561431\n",
      "epoch: 77\n",
      "loss: -2.369428147152366\n",
      "epoch: 78\n",
      "loss: -2.3694281468332177\n",
      "epoch: 79\n",
      "loss: -2.3694281465842275\n",
      "epoch: 80\n",
      "loss: -2.3694281463899767\n",
      "epoch: 81\n",
      "loss: -2.3694281462384317\n",
      "epoch: 82\n",
      "loss: -2.3694281461202045\n",
      "epoch: 83\n",
      "loss: -2.369428146027972\n",
      "epoch: 84\n",
      "loss: -2.3694281459560127\n",
      "epoch: 85\n",
      "loss: -2.3694281458998847\n",
      "epoch: 86\n",
      "loss: -2.3694281458560957\n",
      "epoch: 87\n",
      "loss: -2.3694281458219333\n",
      "epoch: 88\n",
      "loss: -2.3694281457952844\n",
      "epoch: 89\n",
      "loss: -2.3694281457744966\n",
      "epoch: 90\n",
      "loss: -2.3694281457582806\n",
      "epoch: 91\n",
      "loss: -2.369428145745629\n",
      "epoch: 92\n",
      "loss: -2.3694281457357613\n",
      "epoch: 93\n",
      "loss: -2.369428145728062\n",
      "epoch: 94\n",
      "loss: -2.3694281457220563\n",
      "epoch: 95\n",
      "loss: -2.3694281457173734\n",
      "epoch: 96\n",
      "loss: -2.3694281457137176\n",
      "epoch: 97\n",
      "loss: -2.3694281457108657\n",
      "epoch: 98\n",
      "loss: -2.369428145708644\n",
      "epoch: 99\n",
      "loss: -2.369428145706911\n",
      "epoch: 100\n",
      "loss: -2.3694281457055557\n",
      "epoch: 101\n",
      "loss: -2.3694281457045006\n",
      "epoch: 102\n",
      "loss: -2.3694281457036794\n",
      "epoch: 103\n",
      "loss: -2.369428145703034\n",
      "epoch: 104\n",
      "loss: -2.3694281457025355\n",
      "epoch: 105\n",
      "loss: -2.3694281457021438\n",
      "epoch: 106\n",
      "loss: -2.36942814570184\n",
      "epoch: 107\n",
      "loss: -2.369428145701603\n",
      "epoch: 108\n",
      "loss: -2.3694281457014146\n",
      "epoch: 109\n",
      "loss: -2.3694281457012707\n",
      "epoch: 110\n",
      "loss: -2.3694281457011597\n",
      "epoch: 111\n",
      "loss: -2.3694281457010713\n",
      "epoch: 112\n",
      "loss: -2.3694281457010016\n",
      "epoch: 113\n",
      "loss: -2.3694281457009474\n",
      "epoch: 114\n",
      "loss: -2.369428145700906\n",
      "epoch: 115\n",
      "loss: -2.3694281457008737\n",
      "epoch: 116\n",
      "loss: -2.369428145700849\n",
      "epoch: 117\n",
      "loss: -2.3694281457008284\n",
      "epoch: 118\n",
      "loss: -2.369428145700813\n",
      "epoch: 119\n",
      "loss: -2.3694281457008004\n",
      "epoch: 120\n",
      "loss: -2.3694281457007924\n",
      "epoch: 121\n",
      "loss: -2.3694281457007835\n",
      "epoch: 122\n",
      "loss: -2.36942814570078\n",
      "epoch: 123\n",
      "loss: -2.3694281457007755\n",
      "epoch: 124\n",
      "loss: -2.3694281457007715\n",
      "epoch: 125\n",
      "loss: -2.3694281457007698\n",
      "epoch: 126\n",
      "loss: -2.369428145700765\n",
      "epoch: 127\n",
      "loss: -2.369428145700762\n",
      "epoch: 128\n",
      "loss: -2.369428145700763\n",
      "epoch: 129\n",
      "loss: -2.3694281457007627\n",
      "epoch: 130\n",
      "loss: -2.3694281457007627\n",
      "epoch: 131\n",
      "loss: -2.3694281457007618\n",
      "epoch: 132\n",
      "loss: -2.3694281457007613\n",
      "epoch: 133\n",
      "loss: -2.3694281457007595\n",
      "epoch: 134\n",
      "loss: -2.3694281457007595\n",
      "epoch: 135\n",
      "loss: -2.3694281457007587\n",
      "epoch: 136\n",
      "loss: -2.3694281457007578\n",
      "epoch: 137\n",
      "loss: -2.3694281457007587\n",
      "epoch: 138\n",
      "loss: -2.3694281457007578\n",
      "epoch: 139\n",
      "loss: -2.369428145700758\n",
      "epoch: 140\n",
      "loss: -2.3694281457007573\n",
      "epoch: 141\n",
      "loss: -2.3694281457007573\n",
      "epoch: 142\n",
      "loss: -2.3694281457007573\n",
      "epoch: 143\n",
      "loss: -2.3694281457007564\n",
      "epoch: 144\n",
      "loss: -2.3694281457007564\n",
      "epoch: 145\n",
      "loss: -2.3694281457007564\n",
      "epoch: 146\n",
      "loss: -2.3694281457007573\n",
      "epoch: 147\n",
      "loss: -2.3694281457007573\n",
      "epoch: 148\n",
      "loss: -2.3694281457007573\n",
      "epoch: 149\n",
      "loss: -2.3694281457007573\n",
      "epoch: 150\n",
      "loss: -2.3694281457007573\n",
      "epoch: 151\n",
      "loss: -2.3694281457007573\n",
      "epoch: 152\n",
      "loss: -2.3694281457007573\n",
      "epoch: 153\n",
      "loss: -2.3694281457007573\n",
      "epoch: 154\n",
      "loss: -2.3694281457007573\n",
      "epoch: 155\n",
      "loss: -2.3694281457007573\n",
      "epoch: 156\n",
      "loss: -2.3694281457007573\n",
      "epoch: 157\n",
      "loss: -2.3694281457007573\n",
      "epoch: 158\n",
      "loss: -2.3694281457007573\n",
      "epoch: 159\n",
      "loss: -2.3694281457007573\n",
      "epoch: 160\n",
      "loss: -2.3694281457007573\n",
      "epoch: 161\n",
      "loss: -2.3694281457007573\n",
      "epoch: 162\n",
      "loss: -2.3694281457007573\n",
      "epoch: 163\n",
      "loss: -2.3694281457007573\n",
      "epoch: 164\n",
      "loss: -2.3694281457007573\n",
      "epoch: 165\n",
      "loss: -2.3694281457007573\n",
      "epoch: 166\n",
      "loss: -2.3694281457007573\n",
      "epoch: 167\n",
      "loss: -2.3694281457007573\n",
      "epoch: 168\n",
      "loss: -2.3694281457007573\n",
      "epoch: 169\n",
      "loss: -2.3694281457007573\n",
      "epoch: 170\n",
      "loss: -2.3694281457007573\n",
      "epoch: 171\n",
      "loss: -2.3694281457007573\n",
      "epoch: 172\n",
      "loss: -2.3694281457007573\n",
      "epoch: 173\n",
      "loss: -2.3694281457007573\n",
      "epoch: 174\n",
      "loss: -2.3694281457007573\n",
      "epoch: 175\n",
      "loss: -2.3694281457007573\n",
      "epoch: 176\n",
      "loss: -2.3694281457007573\n",
      "epoch: 177\n",
      "loss: -2.3694281457007573\n",
      "epoch: 178\n",
      "loss: -2.3694281457007573\n",
      "epoch: 179\n",
      "loss: -2.3694281457007573\n",
      "epoch: 180\n",
      "loss: -2.3694281457007573\n",
      "epoch: 181\n",
      "loss: -2.3694281457007573\n",
      "epoch: 182\n",
      "loss: -2.3694281457007573\n",
      "epoch: 183\n",
      "loss: -2.3694281457007573\n",
      "epoch: 184\n",
      "loss: -2.3694281457007573\n",
      "epoch: 185\n",
      "loss: -2.3694281457007573\n",
      "epoch: 186\n",
      "loss: -2.3694281457007573\n",
      "epoch: 187\n",
      "loss: -2.3694281457007573\n",
      "epoch: 188\n",
      "loss: -2.3694281457007573\n",
      "epoch: 189\n",
      "loss: -2.3694281457007573\n",
      "epoch: 190\n",
      "loss: -2.3694281457007573\n",
      "epoch: 191\n",
      "loss: -2.3694281457007573\n",
      "epoch: 192\n",
      "loss: -2.3694281457007573\n",
      "epoch: 193\n",
      "loss: -2.3694281457007573\n",
      "epoch: 194\n",
      "loss: -2.3694281457007573\n",
      "epoch: 195\n",
      "loss: -2.3694281457007573\n",
      "epoch: 196\n",
      "loss: -2.3694281457007573\n",
      "epoch: 197\n",
      "loss: -2.3694281457007573\n",
      "epoch: 198\n",
      "loss: -2.3694281457007573\n",
      "epoch: 199\n",
      "loss: -2.3694281457007573\n",
      "epoch: 200\n",
      "loss: -2.3694281457007573\n",
      "epoch: 201\n",
      "loss: -2.3694281457007573\n",
      "epoch: 202\n",
      "loss: -2.3694281457007573\n",
      "epoch: 203\n",
      "loss: -2.3694281457007573\n",
      "epoch: 204\n",
      "loss: -2.3694281457007573\n",
      "epoch: 205\n",
      "loss: -2.3694281457007573\n",
      "epoch: 206\n",
      "loss: -2.3694281457007573\n",
      "epoch: 207\n",
      "loss: -2.3694281457007573\n",
      "epoch: 208\n",
      "loss: -2.3694281457007573\n",
      "epoch: 209\n",
      "loss: -2.3694281457007573\n",
      "epoch: 210\n",
      "loss: -2.3694281457007573\n",
      "epoch: 211\n",
      "loss: -2.3694281457007573\n",
      "epoch: 212\n",
      "loss: -2.3694281457007573\n",
      "epoch: 213\n",
      "loss: -2.3694281457007573\n",
      "epoch: 214\n",
      "loss: -2.3694281457007573\n",
      "epoch: 215\n",
      "loss: -2.3694281457007573\n",
      "epoch: 216\n",
      "loss: -2.3694281457007573\n",
      "epoch: 217\n",
      "loss: -2.3694281457007573\n",
      "epoch: 218\n",
      "loss: -2.3694281457007573\n",
      "epoch: 219\n",
      "loss: -2.3694281457007573\n",
      "epoch: 220\n",
      "loss: -2.3694281457007573\n",
      "epoch: 221\n",
      "loss: -2.3694281457007573\n",
      "epoch: 222\n",
      "loss: -2.3694281457007573\n",
      "epoch: 223\n",
      "loss: -2.3694281457007573\n",
      "epoch: 224\n",
      "loss: -2.3694281457007573\n",
      "epoch: 225\n",
      "loss: -2.3694281457007573\n",
      "epoch: 226\n",
      "loss: -2.3694281457007573\n",
      "epoch: 227\n",
      "loss: -2.3694281457007573\n",
      "epoch: 228\n",
      "loss: -2.3694281457007573\n",
      "epoch: 229\n",
      "loss: -2.3694281457007573\n",
      "epoch: 230\n",
      "loss: -2.3694281457007573\n",
      "epoch: 231\n",
      "loss: -2.3694281457007573\n",
      "epoch: 232\n",
      "loss: -2.3694281457007573\n",
      "epoch: 233\n",
      "loss: -2.3694281457007573\n",
      "epoch: 234\n",
      "loss: -2.3694281457007573\n",
      "epoch: 235\n",
      "loss: -2.3694281457007573\n",
      "epoch: 236\n",
      "loss: -2.3694281457007573\n",
      "epoch: 237\n",
      "loss: -2.3694281457007573\n",
      "epoch: 238\n",
      "loss: -2.3694281457007573\n",
      "epoch: 239\n",
      "loss: -2.3694281457007573\n",
      "epoch: 240\n",
      "loss: -2.3694281457007573\n",
      "epoch: 241\n",
      "loss: -2.3694281457007573\n",
      "epoch: 242\n",
      "loss: -2.3694281457007573\n",
      "epoch: 243\n",
      "loss: -2.3694281457007573\n",
      "epoch: 244\n",
      "loss: -2.3694281457007573\n",
      "epoch: 245\n",
      "loss: -2.3694281457007573\n",
      "epoch: 246\n",
      "loss: -2.3694281457007573\n",
      "epoch: 247\n",
      "loss: -2.3694281457007573\n",
      "epoch: 248\n",
      "loss: -2.3694281457007573\n",
      "epoch: 249\n",
      "loss: -2.3694281457007573\n",
      "epoch: 250\n",
      "loss: -2.3694281457007573\n",
      "epoch: 251\n",
      "loss: -2.3694281457007573\n",
      "epoch: 252\n",
      "loss: -2.3694281457007573\n",
      "epoch: 253\n",
      "loss: -2.3694281457007573\n",
      "epoch: 254\n",
      "loss: -2.3694281457007573\n",
      "epoch: 255\n",
      "loss: -2.3694281457007573\n",
      "epoch: 256\n",
      "loss: -2.3694281457007573\n",
      "epoch: 257\n",
      "loss: -2.3694281457007573\n",
      "epoch: 258\n",
      "loss: -2.3694281457007573\n",
      "epoch: 259\n",
      "loss: -2.3694281457007573\n",
      "epoch: 260\n",
      "loss: -2.3694281457007573\n",
      "epoch: 261\n",
      "loss: -2.3694281457007573\n",
      "epoch: 262\n",
      "loss: -2.3694281457007573\n",
      "epoch: 263\n",
      "loss: -2.3694281457007573\n",
      "epoch: 264\n",
      "loss: -2.3694281457007573\n",
      "epoch: 265\n",
      "loss: -2.3694281457007573\n",
      "epoch: 266\n",
      "loss: -2.3694281457007573\n",
      "epoch: 267\n",
      "loss: -2.3694281457007573\n",
      "epoch: 268\n",
      "loss: -2.3694281457007573\n",
      "epoch: 269\n",
      "loss: -2.3694281457007573\n",
      "epoch: 270\n",
      "loss: -2.3694281457007573\n",
      "epoch: 271\n",
      "loss: -2.3694281457007573\n",
      "epoch: 272\n",
      "loss: -2.3694281457007573\n",
      "epoch: 273\n",
      "loss: -2.3694281457007573\n",
      "epoch: 274\n",
      "loss: -2.3694281457007573\n",
      "epoch: 275\n",
      "loss: -2.3694281457007573\n",
      "epoch: 276\n",
      "loss: -2.3694281457007573\n",
      "epoch: 277\n",
      "loss: -2.3694281457007573\n",
      "epoch: 278\n",
      "loss: -2.3694281457007573\n",
      "epoch: 279\n",
      "loss: -2.3694281457007573\n",
      "epoch: 280\n",
      "loss: -2.3694281457007573\n",
      "epoch: 281\n",
      "loss: -2.3694281457007573\n",
      "epoch: 282\n",
      "loss: -2.3694281457007573\n",
      "epoch: 283\n",
      "loss: -2.3694281457007573\n",
      "epoch: 284\n",
      "loss: -2.3694281457007573\n",
      "epoch: 285\n",
      "loss: -2.3694281457007573\n",
      "epoch: 286\n",
      "loss: -2.3694281457007573\n",
      "epoch: 287\n",
      "loss: -2.3694281457007573\n",
      "epoch: 288\n",
      "loss: -2.3694281457007573\n",
      "epoch: 289\n",
      "loss: -2.3694281457007573\n",
      "epoch: 290\n",
      "loss: -2.3694281457007573\n",
      "epoch: 291\n",
      "loss: -2.3694281457007573\n",
      "epoch: 292\n",
      "loss: -2.3694281457007573\n",
      "epoch: 293\n",
      "loss: -2.3694281457007573\n",
      "epoch: 294\n",
      "loss: -2.3694281457007573\n",
      "epoch: 295\n",
      "loss: -2.3694281457007573\n",
      "epoch: 296\n",
      "loss: -2.3694281457007573\n",
      "epoch: 297\n",
      "loss: -2.3694281457007573\n",
      "epoch: 298\n",
      "loss: -2.3694281457007573\n",
      "epoch: 299\n",
      "loss: -2.3694281457007573\n",
      "epoch: 300\n",
      "loss: -2.3694281457007573\n",
      "epoch: 301\n",
      "loss: -2.3694281457007573\n",
      "epoch: 302\n",
      "loss: -2.3694281457007573\n",
      "epoch: 303\n",
      "loss: -2.3694281457007573\n",
      "epoch: 304\n",
      "loss: -2.3694281457007573\n",
      "epoch: 305\n",
      "loss: -2.3694281457007573\n",
      "epoch: 306\n",
      "loss: -2.3694281457007573\n",
      "epoch: 307\n",
      "loss: -2.3694281457007573\n",
      "epoch: 308\n",
      "loss: -2.3694281457007573\n",
      "epoch: 309\n",
      "loss: -2.3694281457007573\n",
      "epoch: 310\n",
      "loss: -2.3694281457007573\n",
      "epoch: 311\n",
      "loss: -2.3694281457007573\n",
      "epoch: 312\n",
      "loss: -2.3694281457007573\n",
      "epoch: 313\n",
      "loss: -2.3694281457007573\n",
      "epoch: 314\n",
      "loss: -2.3694281457007573\n",
      "epoch: 315\n",
      "loss: -2.3694281457007573\n",
      "epoch: 316\n",
      "loss: -2.3694281457007573\n",
      "epoch: 317\n",
      "loss: -2.3694281457007573\n",
      "epoch: 318\n",
      "loss: -2.3694281457007573\n",
      "epoch: 319\n",
      "loss: -2.3694281457007573\n",
      "epoch: 320\n",
      "loss: -2.3694281457007573\n",
      "epoch: 321\n",
      "loss: -2.3694281457007573\n",
      "epoch: 322\n",
      "loss: -2.3694281457007573\n",
      "epoch: 323\n",
      "loss: -2.3694281457007573\n",
      "epoch: 324\n",
      "loss: -2.3694281457007573\n",
      "epoch: 325\n",
      "loss: -2.3694281457007573\n",
      "epoch: 326\n",
      "loss: -2.3694281457007573\n",
      "epoch: 327\n",
      "loss: -2.3694281457007573\n",
      "epoch: 328\n",
      "loss: -2.3694281457007573\n",
      "epoch: 329\n",
      "loss: -2.3694281457007573\n",
      "epoch: 330\n",
      "loss: -2.3694281457007573\n",
      "epoch: 331\n",
      "loss: -2.3694281457007573\n",
      "epoch: 332\n",
      "loss: -2.3694281457007573\n",
      "epoch: 333\n",
      "loss: -2.3694281457007573\n",
      "epoch: 334\n",
      "loss: -2.3694281457007573\n",
      "epoch: 335\n",
      "loss: -2.3694281457007573\n",
      "epoch: 336\n",
      "loss: -2.3694281457007573\n",
      "epoch: 337\n",
      "loss: -2.3694281457007573\n",
      "epoch: 338\n",
      "loss: -2.3694281457007573\n",
      "epoch: 339\n",
      "loss: -2.3694281457007573\n",
      "epoch: 340\n",
      "loss: -2.3694281457007573\n",
      "epoch: 341\n",
      "loss: -2.3694281457007573\n",
      "epoch: 342\n",
      "loss: -2.3694281457007573\n",
      "epoch: 343\n",
      "loss: -2.3694281457007573\n",
      "epoch: 344\n",
      "loss: -2.3694281457007573\n",
      "epoch: 345\n",
      "loss: -2.3694281457007573\n",
      "epoch: 346\n",
      "loss: -2.3694281457007573\n",
      "epoch: 347\n",
      "loss: -2.3694281457007573\n",
      "epoch: 348\n",
      "loss: -2.3694281457007573\n",
      "epoch: 349\n",
      "loss: -2.3694281457007573\n",
      "epoch: 350\n",
      "loss: -2.3694281457007573\n",
      "epoch: 351\n",
      "loss: -2.3694281457007573\n",
      "epoch: 352\n",
      "loss: -2.3694281457007573\n",
      "epoch: 353\n",
      "loss: -2.3694281457007573\n",
      "epoch: 354\n",
      "loss: -2.3694281457007573\n",
      "epoch: 355\n",
      "loss: -2.3694281457007573\n",
      "epoch: 356\n",
      "loss: -2.3694281457007573\n",
      "epoch: 357\n",
      "loss: -2.3694281457007573\n",
      "epoch: 358\n",
      "loss: -2.3694281457007573\n",
      "epoch: 359\n",
      "loss: -2.3694281457007573\n",
      "epoch: 360\n",
      "loss: -2.3694281457007573\n",
      "epoch: 361\n",
      "loss: -2.3694281457007573\n",
      "epoch: 362\n",
      "loss: -2.3694281457007573\n",
      "epoch: 363\n",
      "loss: -2.3694281457007573\n",
      "epoch: 364\n",
      "loss: -2.3694281457007573\n",
      "epoch: 365\n",
      "loss: -2.3694281457007573\n",
      "epoch: 366\n",
      "loss: -2.3694281457007573\n",
      "epoch: 367\n",
      "loss: -2.3694281457007573\n",
      "epoch: 368\n",
      "loss: -2.3694281457007573\n",
      "epoch: 369\n",
      "loss: -2.3694281457007573\n",
      "epoch: 370\n",
      "loss: -2.3694281457007573\n",
      "epoch: 371\n",
      "loss: -2.3694281457007573\n",
      "epoch: 372\n",
      "loss: -2.3694281457007573\n",
      "epoch: 373\n",
      "loss: -2.3694281457007573\n",
      "epoch: 374\n",
      "loss: -2.3694281457007573\n",
      "epoch: 375\n",
      "loss: -2.3694281457007573\n",
      "epoch: 376\n",
      "loss: -2.3694281457007573\n",
      "epoch: 377\n",
      "loss: -2.3694281457007573\n",
      "epoch: 378\n",
      "loss: -2.3694281457007573\n",
      "epoch: 379\n",
      "loss: -2.3694281457007573\n",
      "epoch: 380\n",
      "loss: -2.3694281457007573\n",
      "epoch: 381\n",
      "loss: -2.3694281457007573\n",
      "epoch: 382\n",
      "loss: -2.3694281457007573\n",
      "epoch: 383\n",
      "loss: -2.3694281457007573\n",
      "epoch: 384\n",
      "loss: -2.3694281457007573\n",
      "epoch: 385\n",
      "loss: -2.3694281457007573\n",
      "epoch: 386\n",
      "loss: -2.3694281457007573\n",
      "epoch: 387\n",
      "loss: -2.3694281457007573\n",
      "epoch: 388\n",
      "loss: -2.3694281457007573\n",
      "epoch: 389\n",
      "loss: -2.3694281457007573\n",
      "epoch: 390\n",
      "loss: -2.3694281457007573\n",
      "epoch: 391\n",
      "loss: -2.3694281457007573\n",
      "epoch: 392\n",
      "loss: -2.3694281457007573\n",
      "epoch: 393\n",
      "loss: -2.3694281457007573\n",
      "epoch: 394\n",
      "loss: -2.3694281457007573\n",
      "epoch: 395\n",
      "loss: -2.3694281457007573\n",
      "epoch: 396\n",
      "loss: -2.3694281457007573\n",
      "epoch: 397\n",
      "loss: -2.3694281457007573\n",
      "epoch: 398\n",
      "loss: -2.3694281457007573\n",
      "epoch: 399\n",
      "loss: -2.3694281457007573\n",
      "epoch: 400\n",
      "loss: -2.3694281457007573\n",
      "epoch: 401\n",
      "loss: -2.3694281457007573\n",
      "epoch: 402\n",
      "loss: -2.3694281457007573\n",
      "epoch: 403\n",
      "loss: -2.3694281457007573\n",
      "epoch: 404\n",
      "loss: -2.3694281457007573\n",
      "epoch: 405\n",
      "loss: -2.3694281457007573\n",
      "epoch: 406\n",
      "loss: -2.3694281457007573\n",
      "epoch: 407\n",
      "loss: -2.3694281457007573\n",
      "epoch: 408\n",
      "loss: -2.3694281457007573\n",
      "epoch: 409\n",
      "loss: -2.3694281457007573\n",
      "epoch: 410\n",
      "loss: -2.3694281457007573\n",
      "epoch: 411\n",
      "loss: -2.3694281457007573\n",
      "epoch: 412\n",
      "loss: -2.3694281457007573\n",
      "epoch: 413\n",
      "loss: -2.3694281457007573\n",
      "epoch: 414\n",
      "loss: -2.3694281457007573\n",
      "epoch: 415\n",
      "loss: -2.3694281457007573\n",
      "epoch: 416\n",
      "loss: -2.3694281457007573\n",
      "epoch: 417\n",
      "loss: -2.3694281457007573\n",
      "epoch: 418\n",
      "loss: -2.3694281457007573\n",
      "epoch: 419\n",
      "loss: -2.3694281457007573\n",
      "epoch: 420\n",
      "loss: -2.3694281457007573\n",
      "epoch: 421\n",
      "loss: -2.3694281457007573\n",
      "epoch: 422\n",
      "loss: -2.3694281457007573\n",
      "epoch: 423\n",
      "loss: -2.3694281457007573\n",
      "epoch: 424\n",
      "loss: -2.3694281457007573\n",
      "epoch: 425\n",
      "loss: -2.3694281457007573\n",
      "epoch: 426\n",
      "loss: -2.3694281457007573\n",
      "epoch: 427\n",
      "loss: -2.3694281457007573\n",
      "epoch: 428\n",
      "loss: -2.3694281457007573\n",
      "epoch: 429\n",
      "loss: -2.3694281457007573\n",
      "epoch: 430\n",
      "loss: -2.3694281457007573\n",
      "epoch: 431\n",
      "loss: -2.3694281457007573\n",
      "epoch: 432\n",
      "loss: -2.3694281457007573\n",
      "epoch: 433\n",
      "loss: -2.3694281457007573\n",
      "epoch: 434\n",
      "loss: -2.3694281457007573\n",
      "epoch: 435\n",
      "loss: -2.3694281457007573\n",
      "epoch: 436\n",
      "loss: -2.3694281457007573\n",
      "epoch: 437\n",
      "loss: -2.3694281457007573\n",
      "epoch: 438\n",
      "loss: -2.3694281457007573\n",
      "epoch: 439\n",
      "loss: -2.3694281457007573\n",
      "epoch: 440\n",
      "loss: -2.3694281457007573\n",
      "epoch: 441\n",
      "loss: -2.3694281457007573\n",
      "epoch: 442\n",
      "loss: -2.3694281457007573\n",
      "epoch: 443\n",
      "loss: -2.3694281457007573\n",
      "epoch: 444\n",
      "loss: -2.3694281457007573\n",
      "epoch: 445\n",
      "loss: -2.3694281457007573\n",
      "epoch: 446\n",
      "loss: -2.3694281457007573\n",
      "epoch: 447\n",
      "loss: -2.3694281457007573\n",
      "epoch: 448\n",
      "loss: -2.3694281457007573\n",
      "epoch: 449\n",
      "loss: -2.3694281457007573\n",
      "epoch: 450\n",
      "loss: -2.3694281457007573\n",
      "epoch: 451\n",
      "loss: -2.3694281457007573\n",
      "epoch: 452\n",
      "loss: -2.3694281457007573\n",
      "epoch: 453\n",
      "loss: -2.3694281457007573\n",
      "epoch: 454\n",
      "loss: -2.3694281457007573\n",
      "epoch: 455\n",
      "loss: -2.3694281457007573\n",
      "epoch: 456\n",
      "loss: -2.3694281457007573\n",
      "epoch: 457\n",
      "loss: -2.3694281457007573\n",
      "epoch: 458\n",
      "loss: -2.3694281457007573\n",
      "epoch: 459\n",
      "loss: -2.3694281457007573\n",
      "epoch: 460\n",
      "loss: -2.3694281457007573\n",
      "epoch: 461\n",
      "loss: -2.3694281457007573\n",
      "epoch: 462\n",
      "loss: -2.3694281457007573\n",
      "epoch: 463\n",
      "loss: -2.3694281457007573\n",
      "epoch: 464\n",
      "loss: -2.3694281457007573\n",
      "epoch: 465\n",
      "loss: -2.3694281457007573\n",
      "epoch: 466\n",
      "loss: -2.3694281457007573\n",
      "epoch: 467\n",
      "loss: -2.3694281457007573\n",
      "epoch: 468\n",
      "loss: -2.3694281457007573\n",
      "epoch: 469\n",
      "loss: -2.3694281457007573\n",
      "epoch: 470\n",
      "loss: -2.3694281457007573\n",
      "epoch: 471\n",
      "loss: -2.3694281457007573\n",
      "epoch: 472\n",
      "loss: -2.3694281457007573\n",
      "epoch: 473\n",
      "loss: -2.3694281457007573\n",
      "epoch: 474\n",
      "loss: -2.3694281457007573\n",
      "epoch: 475\n",
      "loss: -2.3694281457007573\n",
      "epoch: 476\n",
      "loss: -2.3694281457007573\n",
      "epoch: 477\n",
      "loss: -2.3694281457007573\n",
      "epoch: 478\n",
      "loss: -2.3694281457007573\n",
      "epoch: 479\n",
      "loss: -2.3694281457007573\n",
      "epoch: 480\n",
      "loss: -2.3694281457007573\n",
      "epoch: 481\n",
      "loss: -2.3694281457007573\n",
      "epoch: 482\n",
      "loss: -2.3694281457007573\n",
      "epoch: 483\n",
      "loss: -2.3694281457007573\n",
      "epoch: 484\n",
      "loss: -2.3694281457007573\n",
      "epoch: 485\n",
      "loss: -2.3694281457007573\n",
      "epoch: 486\n",
      "loss: -2.3694281457007573\n",
      "epoch: 487\n",
      "loss: -2.3694281457007573\n",
      "epoch: 488\n",
      "loss: -2.3694281457007573\n",
      "epoch: 489\n",
      "loss: -2.3694281457007573\n",
      "epoch: 490\n",
      "loss: -2.3694281457007573\n",
      "epoch: 491\n",
      "loss: -2.3694281457007573\n",
      "epoch: 492\n",
      "loss: -2.3694281457007573\n",
      "epoch: 493\n",
      "loss: -2.3694281457007573\n",
      "epoch: 494\n",
      "loss: -2.3694281457007573\n",
      "epoch: 495\n",
      "loss: -2.3694281457007573\n",
      "epoch: 496\n",
      "loss: -2.3694281457007573\n",
      "epoch: 497\n",
      "loss: -2.3694281457007573\n",
      "epoch: 498\n",
      "loss: -2.3694281457007573\n",
      "epoch: 499\n",
      "loss: -2.3694281457007573\n"
     ]
    }
   ],
   "source": [
    "model = PolynomialRegressionModel(3)\n",
    "model.fit(train['X'], train['Y'], lr=0.01, epochs=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
